{"config":{"indexing":"full","lang":["fr"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Babushka ML Credit by Daisuke Kuwabara Babushka ML is organized by Daisuke Kuwabara aiming at spreading the best practice for ML","title":"Home"},{"location":"#welcome-to-babushka-ml","text":"Credit by Daisuke Kuwabara Babushka ML is organized by Daisuke Kuwabara aiming at spreading the best practice for ML","title":"Welcome to Babushka ML"},{"location":"course/","text":"Python Programming Introduction to Python3 Object Oriented Programming Decorators and Callback Software Engineering Linux RESTful API with Fast API and Uvicorn Graph Database - NoSQL Docker and Operation System Kubernetes and its components Testing(Parametrize, Fixtures, Markers, Coverage) Production Networking TCP/IP model Machine Learning Engineer Dashboard using Streamlit Data Versioning with DVC CI/CD Workflows with GitHub Actions Google's MLOps Feature Store with Feast Pipelines with Kubeflow Monitoring ML Systems Data Engineer BigQuery and SQL Batch/Streaming Processing with Apache Beam Messaging System with Pub/Sub Apache Airflow with Cloud Composer Hadoop/Spark Ecosystem with Dataproc Data Science Probability and Statistics Mathematics Continuous Optimization Time-Series Analysis Survival Analysis using R Neural Network Convolutional Neural Network Deep Learning Price Babushka ML is focusing on human factors in the first place. As such, the price of each course is detemined by the dynamic pricing, which means you can directly negotiate up to your satisfaction. About Daisuke Kuwabara - Data Specialist at EPAM Systems - Master in Data Science - Google Cloud Professional Data Engineer - AWS Solution Architect Associates","title":"Course"},{"location":"course/#python-programming","text":"Introduction to Python3 Object Oriented Programming Decorators and Callback","title":"Python Programming"},{"location":"course/#software-engineering","text":"Linux RESTful API with Fast API and Uvicorn Graph Database - NoSQL Docker and Operation System Kubernetes and its components Testing(Parametrize, Fixtures, Markers, Coverage) Production","title":"Software Engineering"},{"location":"course/#networking","text":"TCP/IP model","title":"Networking"},{"location":"course/#machine-learning-engineer","text":"Dashboard using Streamlit Data Versioning with DVC CI/CD Workflows with GitHub Actions Google's MLOps Feature Store with Feast Pipelines with Kubeflow Monitoring ML Systems","title":"Machine Learning Engineer"},{"location":"course/#data-engineer","text":"BigQuery and SQL Batch/Streaming Processing with Apache Beam Messaging System with Pub/Sub Apache Airflow with Cloud Composer Hadoop/Spark Ecosystem with Dataproc","title":"Data Engineer"},{"location":"course/#data-science","text":"Probability and Statistics Mathematics Continuous Optimization Time-Series Analysis Survival Analysis using R Neural Network Convolutional Neural Network Deep Learning","title":"Data Science"},{"location":"course/#price","text":"Babushka ML is focusing on human factors in the first place. As such, the price of each course is detemined by the dynamic pricing, which means you can directly negotiate up to your satisfaction.","title":"Price"},{"location":"course/#about-daisuke-kuwabara","text":"- Data Specialist at EPAM Systems - Master in Data Science - Google Cloud Professional Data Engineer - AWS Solution Architect Associates","title":"About Daisuke Kuwabara"},{"location":"daisuke/","text":"Working with various clients(including Amazon, Google) supporting the technical challenges with hands-on guide using his knowledge from Master in Science and EPAM Systems Born in Japan, grown up in South France city, Montpellier the imagination is from the inspiration in every moment he lives, feels, experiences materliazed into the creative entity which delivers the contents. Fundamental question is what you achieve in your life. No matter who you are, where you are... Experiences Full Stack Data Scientist at EPAM Systems Data Scientist & Computer Vision Engineer at Startup MSc in Data Science & Artificial Intelligence at Data ScienceTech Institute Contact EMAIL: daisuke0582@gmail.com Phone: +81 90 9293 4580","title":"About Daisuke Kuwabara"},{"location":"daisuke/#experiences","text":"Full Stack Data Scientist at EPAM Systems Data Scientist & Computer Vision Engineer at Startup MSc in Data Science & Artificial Intelligence at Data ScienceTech Institute","title":"Experiences"},{"location":"daisuke/#contact","text":"EMAIL: daisuke0582@gmail.com Phone: +81 90 9293 4580","title":"Contact"},{"location":"blog/airflow/","text":"Airflow Apache Airflow (or simply Airflow) is a platform to programmatically author, schedule, and monitor workflows. You could orchestrate the task as Directed Acyclic Graph data_orchestration.py from airflow import models from airflow.hooks.base import BaseHook from airflow.providers.google.cloud.operators.bigquery import BigQueryCheckOperator from airflow.providers.google.cloud.operators.dataflow import DataflowTemplatedJobStartOperator from airflow.providers.google.cloud.sensors.gcs import GCSObjectExistenceSensor from airflow.providers.slack.operators.slack_webhook import SlackWebhookOperator from airflow.utils.dates import days_ago from airflow.utils.state import State # Sample data BUCKET_NAME = \"cloud-samples-data/composer/data-orchestration-blog-example\" DATA_FILE_NAME = \"bike_station_data.csv\" # Assumes existence of the following Airflow Variables PROJECT_ID = models . Variable . get ( \"gcp_project\" ) DATASET = models . Variable . get ( \"bigquery_dataset\" ) TABLE = models . Variable . get ( \"bigquery_table\" ) # Slack error notification example taken from Kaxil Naik's blog on Slack Integration: # https://medium.com/datareply/integrating-slack-alerts-in-airflow-c9dcd155105 def on_failure_callback ( context ): ti = context . get ( \"task_instance\" ) slack_msg = f \"\"\" :red_circle: Task Failed. *Task*: { ti . task_id } *Dag*: { ti . dag_id } *Execution Time*: { context . get ( 'execution_date' ) } *Log Url*: { ti . log_url } \"\"\" slack_webhook_token = BaseHook . get_connection ( \"slack_connection\" ) . password slack_error = SlackWebhookOperator ( task_id = \"post_slack_error\" , http_conn_id = \"slack_connection\" , channel = \"#airflow-alerts\" , webhook_token = slack_webhook_token , message = slack_msg , ) slack_error . execute ( context ) with models . DAG ( \"dataflow_to_bq_workflow\" , schedule_interval = None , start_date = days_ago ( 1 ), default_args = { \"on_failure_callback\" : on_failure_callback }, ) as dag : validate_file_exists = GCSObjectExistenceSensor ( task_id = \"validate_file_exists\" , bucket = BUCKET_NAME , object = DATA_FILE_NAME ) # See Launching Dataflow pipelines with Cloud Composer tutorial for further guidance # https://cloud.google.com/composer/docs/how-to/using/using-dataflow-template-operator start_dataflow_job = DataflowTemplatedJobStartOperator ( task_id = \"start-dataflow-template-job\" , job_name = \"csv_to_bq_transform\" , template = \"gs://dataflow-templates/latest/GCS_Text_to_BigQuery\" , parameters = { \"javascriptTextTransformFunctionName\" : \"transform\" , \"javascriptTextTransformGcsPath\" : f \"gs:// { BUCKET_NAME } /udf_transform.js\" , \"JSONPath\" : f \"gs:// { BUCKET_NAME } /bq_schema.json\" , \"inputFilePattern\" : f \"gs:// { BUCKET_NAME } / { DATA_FILE_NAME } \" , \"bigQueryLoadingTemporaryDirectory\" : f \"gs:// { BUCKET_NAME } /tmp/\" , \"outputTable\" : f \" { PROJECT_ID } : { DATASET } . { TABLE } \" , }, ) execute_bigquery_sql = BigQueryCheckOperator ( task_id = \"execute_bigquery_sql\" , sql = f \"SELECT COUNT(*) FROM ` { PROJECT_ID } . { DATASET } . { TABLE } `\" , use_legacy_sql = False , ) validate_file_exists >> start_dataflow_job >> execute_bigquery_sql if __name__ == \"__main__\" : dag . clear ( dag_run_state = State . NONE ) dag . run () Approach Astronomer Astronomer is the commercial developer of Apache Airflow, a community-driven open-source tool that's leading the market in data orchestration. We're a globally-distributed and rapidly growing venture-backed team of learners, innovators and collaborators. Cloud Composer Cloud Composer is a fully managed workflow orchestration service built on Apache Airflow in Google Cloud Platform Amazon Managed Workflows for Apache Airflow(MWAA) Amazon Managed Workflows for Apache Airflow (MWAA) is a managed orchestration service for Apache Airflow1 that makes it easier to set up and operate end-to-end data pipelines in the cloud at scale. Apache Airflow is an open-source tool used to programmatically author, schedule, and monitor sequences of processes and tasks referred to as \u201cworkflows.\u201d in Amazon Web Service.","title":"Airflow"},{"location":"blog/airflow/#airflow","text":"Apache Airflow (or simply Airflow) is a platform to programmatically author, schedule, and monitor workflows. You could orchestrate the task as Directed Acyclic Graph data_orchestration.py from airflow import models from airflow.hooks.base import BaseHook from airflow.providers.google.cloud.operators.bigquery import BigQueryCheckOperator from airflow.providers.google.cloud.operators.dataflow import DataflowTemplatedJobStartOperator from airflow.providers.google.cloud.sensors.gcs import GCSObjectExistenceSensor from airflow.providers.slack.operators.slack_webhook import SlackWebhookOperator from airflow.utils.dates import days_ago from airflow.utils.state import State # Sample data BUCKET_NAME = \"cloud-samples-data/composer/data-orchestration-blog-example\" DATA_FILE_NAME = \"bike_station_data.csv\" # Assumes existence of the following Airflow Variables PROJECT_ID = models . Variable . get ( \"gcp_project\" ) DATASET = models . Variable . get ( \"bigquery_dataset\" ) TABLE = models . Variable . get ( \"bigquery_table\" ) # Slack error notification example taken from Kaxil Naik's blog on Slack Integration: # https://medium.com/datareply/integrating-slack-alerts-in-airflow-c9dcd155105 def on_failure_callback ( context ): ti = context . get ( \"task_instance\" ) slack_msg = f \"\"\" :red_circle: Task Failed. *Task*: { ti . task_id } *Dag*: { ti . dag_id } *Execution Time*: { context . get ( 'execution_date' ) } *Log Url*: { ti . log_url } \"\"\" slack_webhook_token = BaseHook . get_connection ( \"slack_connection\" ) . password slack_error = SlackWebhookOperator ( task_id = \"post_slack_error\" , http_conn_id = \"slack_connection\" , channel = \"#airflow-alerts\" , webhook_token = slack_webhook_token , message = slack_msg , ) slack_error . execute ( context ) with models . DAG ( \"dataflow_to_bq_workflow\" , schedule_interval = None , start_date = days_ago ( 1 ), default_args = { \"on_failure_callback\" : on_failure_callback }, ) as dag : validate_file_exists = GCSObjectExistenceSensor ( task_id = \"validate_file_exists\" , bucket = BUCKET_NAME , object = DATA_FILE_NAME ) # See Launching Dataflow pipelines with Cloud Composer tutorial for further guidance # https://cloud.google.com/composer/docs/how-to/using/using-dataflow-template-operator start_dataflow_job = DataflowTemplatedJobStartOperator ( task_id = \"start-dataflow-template-job\" , job_name = \"csv_to_bq_transform\" , template = \"gs://dataflow-templates/latest/GCS_Text_to_BigQuery\" , parameters = { \"javascriptTextTransformFunctionName\" : \"transform\" , \"javascriptTextTransformGcsPath\" : f \"gs:// { BUCKET_NAME } /udf_transform.js\" , \"JSONPath\" : f \"gs:// { BUCKET_NAME } /bq_schema.json\" , \"inputFilePattern\" : f \"gs:// { BUCKET_NAME } / { DATA_FILE_NAME } \" , \"bigQueryLoadingTemporaryDirectory\" : f \"gs:// { BUCKET_NAME } /tmp/\" , \"outputTable\" : f \" { PROJECT_ID } : { DATASET } . { TABLE } \" , }, ) execute_bigquery_sql = BigQueryCheckOperator ( task_id = \"execute_bigquery_sql\" , sql = f \"SELECT COUNT(*) FROM ` { PROJECT_ID } . { DATASET } . { TABLE } `\" , use_legacy_sql = False , ) validate_file_exists >> start_dataflow_job >> execute_bigquery_sql if __name__ == \"__main__\" : dag . clear ( dag_run_state = State . NONE ) dag . run ()","title":"Airflow"},{"location":"blog/airflow/#approach","text":"Astronomer Astronomer is the commercial developer of Apache Airflow, a community-driven open-source tool that's leading the market in data orchestration. We're a globally-distributed and rapidly growing venture-backed team of learners, innovators and collaborators. Cloud Composer Cloud Composer is a fully managed workflow orchestration service built on Apache Airflow in Google Cloud Platform Amazon Managed Workflows for Apache Airflow(MWAA) Amazon Managed Workflows for Apache Airflow (MWAA) is a managed orchestration service for Apache Airflow1 that makes it easier to set up and operate end-to-end data pipelines in the cloud at scale. Apache Airflow is an open-source tool used to programmatically author, schedule, and monitor sequences of processes and tasks referred to as \u201cworkflows.\u201d in Amazon Web Service.","title":"Approach"},{"location":"blog/babushka/","text":"Why Babushka? Old woman holding vegetables is wearing Babushka Babushka refers to a woman's scarf, as well as an elderly Russian woman. The symbolic trend of Babushka is widely known as Babushka Boi by A$AP Rocky. The cultural tribute is the center of Babushka ML . Machine Learning is the heritage of thousands years of study in the various field, blooming by virtue of modern hardware development. Babushka ML is established on the heritage of our progressivity and ingenuity.","title":"Why Babushka?"},{"location":"blog/babushka/#why-babushka","text":"Old woman holding vegetables is wearing Babushka Babushka refers to a woman's scarf, as well as an elderly Russian woman. The symbolic trend of Babushka is widely known as Babushka Boi by A$AP Rocky. The cultural tribute is the center of Babushka ML . Machine Learning is the heritage of thousands years of study in the various field, blooming by virtue of modern hardware development. Babushka ML is established on the heritage of our progressivity and ingenuity.","title":"Why Babushka?"},{"location":"blog/data_engineer/","text":"Reconsider Machine Learning Being Machine Learning Engineer requires the significant efforts and expertises on skills. Are you ready to start your journey...?","title":"Data Engineer"},{"location":"blog/data_engineer/#reconsider-machine-learning","text":"Being Machine Learning Engineer requires the significant efforts and expertises on skills. Are you ready to start your journey...?","title":"Reconsider Machine Learning"}]}